"""
LLM/Chat Model Pricing Configuration

This module contains pricing information for LLM (Large Language Model) and chat models
across different providers (OpenAI, Anthropic, etc.).

Separated from model_pricing.py for better organization as the model list grows.
"""

from typing import Dict, Optional, Any
try:
    # Try relative import first (when running as module)
    from .model_pricing import (
        ModelPricing,
        ModelType,
        Provider,
        RateLimit,
    )
except ImportError:
    # Fallback to absolute import (when running directly)
    from backend.utils.model_pricing import (
        ModelPricing,
        ModelType,
        Provider,
        RateLimit,
    )


# ============================================================================
# OPENAI LLM MODELS
# ============================================================================

OPENAI_LLM_MODELS: Dict[str, ModelPricing] = {
    # GPT-5 Series (Frontier Models)
    "gpt-5.1": ModelPricing(
        model_id="gpt-5.1",
        provider=Provider.OPENAI,
        model_type=ModelType.LLM,
        price_per_1k_tokens=None,  # LLMs use separate input/output pricing
        max_tokens=128000,  # 128k context
        description="The best model for coding and agentic tasks with configurable reasoning effort",
        metadata={
            "input_price_per_1m_tokens": 1.25,
            "cached_input_price_per_1m_tokens": 0.125,
            "output_price_per_1m_tokens": 10.00,
            "input_price_per_1k_tokens": 1.25 / 1000,  # $0.00125 per 1K tokens
            "cached_input_price_per_1k_tokens": 0.125 / 1000,  # $0.000125 per 1K tokens
            "output_price_per_1k_tokens": 10.00 / 1000,  # $0.01 per 1K tokens
            "category": "frontier",
            "features": ["reasoning", "coding", "agentic"],
        },
    ),
    "gpt-5": ModelPricing(
        model_id="gpt-5",
        provider=Provider.OPENAI,
        model_type=ModelType.LLM,
        price_per_1k_tokens=None,
        max_tokens=128000,
        description="Previous intelligent reasoning model for coding and agentic tasks with configurable reasoning effort",
        metadata={
            "input_price_per_1m_tokens": 1.25,
            "cached_input_price_per_1m_tokens": 0.125,
            "output_price_per_1m_tokens": 10.00,
            "input_price_per_1k_tokens": 1.25 / 1000,
            "cached_input_price_per_1k_tokens": 0.125 / 1000,
            "output_price_per_1k_tokens": 10.00 / 1000,
            "category": "frontier",
            "features": ["reasoning", "coding", "agentic"],
        },
    ),
    "gpt-5-mini": ModelPricing(
        model_id="gpt-5-mini",
        provider=Provider.OPENAI,
        model_type=ModelType.LLM,
        price_per_1k_tokens=None,
        max_tokens=128000,
        description="A faster, cost-efficient version of GPT-5 for well-defined tasks",
        metadata={
            "input_price_per_1m_tokens": 0.25,
            "cached_input_price_per_1m_tokens": 0.025,
            "output_price_per_1m_tokens": 2.00,
            "input_price_per_1k_tokens": 0.25 / 1000,
            "cached_input_price_per_1k_tokens": 0.025 / 1000,
            "output_price_per_1k_tokens": 2.00 / 1000,
            "category": "frontier",
            "features": ["reasoning", "coding", "agentic"],
        },
    ),
    "gpt-5-nano": ModelPricing(
        model_id="gpt-5-nano",
        provider=Provider.OPENAI,
        model_type=ModelType.LLM,
        price_per_1k_tokens=None,
        max_tokens=128000,
        description="Fastest, most cost-efficient version of GPT-5",
        metadata={
            "input_price_per_1m_tokens": 0.05,
            "cached_input_price_per_1m_tokens": 0.005,
            "output_price_per_1m_tokens": 0.40,
            "input_price_per_1k_tokens": 0.05 / 1000,
            "cached_input_price_per_1k_tokens": 0.005 / 1000,
            "output_price_per_1k_tokens": 0.40 / 1000,
            "category": "frontier",
            "features": ["reasoning", "coding", "agentic"],
        },
    ),
    "gpt-5-pro": ModelPricing(
        model_id="gpt-5-pro",
        provider=Provider.OPENAI,
        model_type=ModelType.LLM,
        price_per_1k_tokens=None,
        max_tokens=128000,
        description="Version of GPT-5 that produces smarter and more precise responses",
        metadata={
            "input_price_per_1m_tokens": 15.00,
            "cached_input_price_per_1m_tokens": None,  # No cached pricing
            "output_price_per_1m_tokens": 120.00,
            "input_price_per_1k_tokens": 15.00 / 1000,
            "cached_input_price_per_1k_tokens": None,
            "output_price_per_1k_tokens": 120.00 / 1000,
            "category": "frontier",
            "features": ["reasoning", "coding", "agentic"],
        },
    ),
    "gpt-5.1-chat-latest": ModelPricing(
        model_id="gpt-5.1-chat-latest",
        provider=Provider.OPENAI,
        model_type=ModelType.LLM,
        price_per_1k_tokens=None,
        max_tokens=128000,
        description="GPT-5.1 model used in ChatGPT",
        metadata={
            "input_price_per_1m_tokens": 1.25,
            "cached_input_price_per_1m_tokens": 0.125,
            "output_price_per_1m_tokens": 10.00,
            "input_price_per_1k_tokens": 1.25 / 1000,
            "cached_input_price_per_1k_tokens": 0.125 / 1000,
            "output_price_per_1k_tokens": 10.00 / 1000,
            "category": "frontier",
            "features": ["chat", "reasoning"],
        },
    ),
    "gpt-5-chat-latest": ModelPricing(
        model_id="gpt-5-chat-latest",
        provider=Provider.OPENAI,
        model_type=ModelType.LLM,
        price_per_1k_tokens=None,
        max_tokens=128000,
        description="GPT-5 model used in ChatGPT",
        metadata={
            "input_price_per_1m_tokens": 1.25,
            "cached_input_price_per_1m_tokens": 0.125,
            "output_price_per_1m_tokens": 10.00,
            "input_price_per_1k_tokens": 1.25 / 1000,
            "cached_input_price_per_1k_tokens": 0.125 / 1000,
            "output_price_per_1k_tokens": 10.00 / 1000,
            "category": "frontier",
            "features": ["chat", "reasoning"],
        },
    ),
    "gpt-5.1-codex": ModelPricing(
        model_id="gpt-5.1-codex",
        provider=Provider.OPENAI,
        model_type=ModelType.LLM,
        price_per_1k_tokens=None,
        max_tokens=128000,
        description="A version of GPT-5.1 optimized for agentic coding in Codex",
        metadata={
            "input_price_per_1m_tokens": 1.25,
            "cached_input_price_per_1m_tokens": 0.125,
            "output_price_per_1m_tokens": 10.00,
            "input_price_per_1k_tokens": 1.25 / 1000,
            "cached_input_price_per_1k_tokens": 0.125 / 1000,
            "output_price_per_1k_tokens": 10.00 / 1000,
            "category": "frontier",
            "features": ["coding", "agentic"],
        },
    ),
    "gpt-5-codex": ModelPricing(
        model_id="gpt-5-codex",
        provider=Provider.OPENAI,
        model_type=ModelType.LLM,
        price_per_1k_tokens=None,
        max_tokens=128000,
        description="A version of GPT-5 optimized for agentic coding in Codex",
        metadata={
            "input_price_per_1m_tokens": 1.25,
            "cached_input_price_per_1m_tokens": 0.125,
            "output_price_per_1m_tokens": 10.00,
            "input_price_per_1k_tokens": 1.25 / 1000,
            "cached_input_price_per_1k_tokens": 0.125 / 1000,
            "output_price_per_1k_tokens": 10.00 / 1000,
            "category": "frontier",
            "features": ["coding", "agentic"],
        },
    ),
    "gpt-5.1-codex-mini": ModelPricing(
        model_id="gpt-5.1-codex-mini",
        provider=Provider.OPENAI,
        model_type=ModelType.LLM,
        price_per_1k_tokens=None,
        max_tokens=128000,
        description="Smaller, more cost-effective, less-capable version of GPT-5.1-Codex",
        metadata={
            "input_price_per_1m_tokens": 0.25,
            "cached_input_price_per_1m_tokens": 0.025,
            "output_price_per_1m_tokens": 2.00,
            "input_price_per_1k_tokens": 0.25 / 1000,
            "cached_input_price_per_1k_tokens": 0.025 / 1000,
            "output_price_per_1k_tokens": 2.00 / 1000,
            "category": "frontier",
            "features": ["coding", "agentic"],
        },
    ),
    
    # GPT-4.1 Series
    "gpt-4.1": ModelPricing(
        model_id="gpt-4.1",
        provider=Provider.OPENAI,
        model_type=ModelType.LLM,
        price_per_1k_tokens=None,
        max_tokens=128000,
        description="Smartest non-reasoning model",
        metadata={
            "input_price_per_1m_tokens": 2.00,
            "cached_input_price_per_1m_tokens": 0.50,
            "output_price_per_1m_tokens": 8.00,
            "input_price_per_1k_tokens": 2.00 / 1000,
            "cached_input_price_per_1k_tokens": 0.50 / 1000,
            "output_price_per_1k_tokens": 8.00 / 1000,
            "category": "frontier",
        },
    ),
    "gpt-4.1-mini": ModelPricing(
        model_id="gpt-4.1-mini",
        provider=Provider.OPENAI,
        model_type=ModelType.LLM,
        price_per_1k_tokens=None,
        max_tokens=128000,
        description="Smaller, faster version of GPT-4.1",
        metadata={
            "input_price_per_1m_tokens": 0.40,
            "cached_input_price_per_1m_tokens": 0.10,
            "output_price_per_1m_tokens": 1.60,
            "input_price_per_1k_tokens": 0.40 / 1000,
            "cached_input_price_per_1k_tokens": 0.10 / 1000,
            "output_price_per_1k_tokens": 1.60 / 1000,
            "category": "frontier",
        },
    ),
    "gpt-4.1-nano": ModelPricing(
        model_id="gpt-4.1-nano",
        provider=Provider.OPENAI,
        model_type=ModelType.LLM,
        price_per_1k_tokens=None,
        max_tokens=128000,
        description="Fastest, most cost-efficient version of GPT-4.1",
        metadata={
            "input_price_per_1m_tokens": 0.10,
            "cached_input_price_per_1m_tokens": 0.025,
            "output_price_per_1m_tokens": 0.40,
            "input_price_per_1k_tokens": 0.10 / 1000,
            "cached_input_price_per_1k_tokens": 0.025 / 1000,
            "output_price_per_1k_tokens": 0.40 / 1000,
            "category": "frontier",
        },
    ),
    
    # GPT-4o Series
    "gpt-4o": ModelPricing(
        model_id="gpt-4o",
        provider=Provider.OPENAI,
        model_type=ModelType.LLM,
        price_per_1k_tokens=None,
        max_tokens=128000,
        description="Fast, intelligent, flexible GPT model",
        metadata={
            "input_price_per_1m_tokens": 2.50,
            "cached_input_price_per_1m_tokens": 1.25,
            "output_price_per_1m_tokens": 10.00,
            "input_price_per_1k_tokens": 2.50 / 1000,
            "cached_input_price_per_1k_tokens": 1.25 / 1000,
            "output_price_per_1k_tokens": 10.00 / 1000,
            "category": "standard",
        },
    ),
    "gpt-4o-2024-05-13": ModelPricing(
        model_id="gpt-4o-2024-05-13",
        provider=Provider.OPENAI,
        model_type=ModelType.LLM,
        price_per_1k_tokens=None,
        max_tokens=128000,
        description="GPT-4o snapshot from May 13, 2024",
        metadata={
            "input_price_per_1m_tokens": 5.00,
            "cached_input_price_per_1m_tokens": None,
            "output_price_per_1m_tokens": 15.00,
            "input_price_per_1k_tokens": 5.00 / 1000,
            "cached_input_price_per_1k_tokens": None,
            "output_price_per_1k_tokens": 15.00 / 1000,
            "category": "standard",
        },
    ),
    "gpt-4o-mini": ModelPricing(
        model_id="gpt-4o-mini",
        provider=Provider.OPENAI,
        model_type=ModelType.LLM,
        price_per_1k_tokens=None,
        max_tokens=128000,
        description="Fast, affordable small model for focused tasks",
        metadata={
            "input_price_per_1m_tokens": 0.15,
            "cached_input_price_per_1m_tokens": 0.075,
            "output_price_per_1m_tokens": 0.60,
            "input_price_per_1k_tokens": 0.15 / 1000,
            "cached_input_price_per_1k_tokens": 0.075 / 1000,
            "output_price_per_1k_tokens": 0.60 / 1000,
            "category": "standard",
        },
    ),
    
    # Realtime Models
    "gpt-realtime": ModelPricing(
        model_id="gpt-realtime",
        provider=Provider.OPENAI,
        model_type=ModelType.LLM,
        price_per_1k_tokens=None,
        max_tokens=128000,
        description="Model capable of realtime text and audio inputs and outputs",
        metadata={
            "input_price_per_1m_tokens": 4.00,
            "cached_input_price_per_1m_tokens": 0.40,
            "output_price_per_1m_tokens": 16.00,
            "input_price_per_1k_tokens": 4.00 / 1000,
            "cached_input_price_per_1k_tokens": 0.40 / 1000,
            "output_price_per_1k_tokens": 16.00 / 1000,
            "category": "specialized",
            "features": ["realtime", "audio"],
        },
    ),
    "gpt-realtime-mini": ModelPricing(
        model_id="gpt-realtime-mini",
        provider=Provider.OPENAI,
        model_type=ModelType.LLM,
        price_per_1k_tokens=None,
        max_tokens=128000,
        description="A cost-efficient version of GPT Realtime",
        metadata={
            "input_price_per_1m_tokens": 0.60,
            "cached_input_price_per_1m_tokens": 0.06,
            "output_price_per_1m_tokens": 2.40,
            "input_price_per_1k_tokens": 0.60 / 1000,
            "cached_input_price_per_1k_tokens": 0.06 / 1000,
            "output_price_per_1k_tokens": 2.40 / 1000,
            "category": "specialized",
            "features": ["realtime", "audio"],
        },
    ),
    "gpt-4o-realtime-preview": ModelPricing(
        model_id="gpt-4o-realtime-preview",
        provider=Provider.OPENAI,
        model_type=ModelType.LLM,
        price_per_1k_tokens=None,
        max_tokens=128000,
        description="Model capable of realtime text and audio inputs and outputs",
        metadata={
            "input_price_per_1m_tokens": 5.00,
            "cached_input_price_per_1m_tokens": 2.50,
            "output_price_per_1m_tokens": 20.00,
            "input_price_per_1k_tokens": 5.00 / 1000,
            "cached_input_price_per_1k_tokens": 2.50 / 1000,
            "output_price_per_1k_tokens": 20.00 / 1000,
            "category": "specialized",
            "features": ["realtime", "audio"],
        },
    ),
    "gpt-4o-mini-realtime-preview": ModelPricing(
        model_id="gpt-4o-mini-realtime-preview",
        provider=Provider.OPENAI,
        model_type=ModelType.LLM,
        price_per_1k_tokens=None,
        max_tokens=128000,
        description="Smaller realtime model for text and audio inputs and outputs",
        metadata={
            "input_price_per_1m_tokens": 0.60,
            "cached_input_price_per_1m_tokens": 0.30,
            "output_price_per_1m_tokens": 2.40,
            "input_price_per_1k_tokens": 0.60 / 1000,
            "cached_input_price_per_1k_tokens": 0.30 / 1000,
            "output_price_per_1k_tokens": 2.40 / 1000,
            "category": "specialized",
            "features": ["realtime", "audio"],
        },
    ),
    
    # Audio Models
    "gpt-audio": ModelPricing(
        model_id="gpt-audio",
        provider=Provider.OPENAI,
        model_type=ModelType.LLM,
        price_per_1k_tokens=None,
        max_tokens=128000,
        description="For audio inputs and outputs with Chat Completions API",
        metadata={
            "input_price_per_1m_tokens": 2.50,
            "cached_input_price_per_1m_tokens": None,
            "output_price_per_1m_tokens": 10.00,
            "input_price_per_1k_tokens": 2.50 / 1000,
            "cached_input_price_per_1k_tokens": None,
            "output_price_per_1k_tokens": 10.00 / 1000,
            "category": "specialized",
            "features": ["audio"],
        },
    ),
    "gpt-audio-mini": ModelPricing(
        model_id="gpt-audio-mini",
        provider=Provider.OPENAI,
        model_type=ModelType.LLM,
        price_per_1k_tokens=None,
        max_tokens=128000,
        description="A cost-efficient version of GPT Audio",
        metadata={
            "input_price_per_1m_tokens": 0.60,
            "cached_input_price_per_1m_tokens": None,
            "output_price_per_1m_tokens": 2.40,
            "input_price_per_1k_tokens": 0.60 / 1000,
            "cached_input_price_per_1k_tokens": None,
            "output_price_per_1k_tokens": 2.40 / 1000,
            "category": "specialized",
            "features": ["audio"],
        },
    ),
    "gpt-4o-audio-preview": ModelPricing(
        model_id="gpt-4o-audio-preview",
        provider=Provider.OPENAI,
        model_type=ModelType.LLM,
        price_per_1k_tokens=None,
        max_tokens=128000,
        description="GPT-4o models capable of audio inputs and outputs",
        metadata={
            "input_price_per_1m_tokens": 2.50,
            "cached_input_price_per_1m_tokens": None,
            "output_price_per_1m_tokens": 10.00,
            "input_price_per_1k_tokens": 2.50 / 1000,
            "cached_input_price_per_1k_tokens": None,
            "output_price_per_1k_tokens": 10.00 / 1000,
            "category": "specialized",
            "features": ["audio"],
        },
    ),
    "gpt-4o-mini-audio-preview": ModelPricing(
        model_id="gpt-4o-mini-audio-preview",
        provider=Provider.OPENAI,
        model_type=ModelType.LLM,
        price_per_1k_tokens=None,
        max_tokens=128000,
        description="Smaller model capable of audio inputs and outputs",
        metadata={
            "input_price_per_1m_tokens": 0.15,
            "cached_input_price_per_1m_tokens": None,
            "output_price_per_1m_tokens": 0.60,
            "input_price_per_1k_tokens": 0.15 / 1000,
            "cached_input_price_per_1k_tokens": None,
            "output_price_per_1k_tokens": 0.60 / 1000,
            "category": "specialized",
            "features": ["audio"],
        },
    ),
    
    # O-Series Reasoning Models
    "o1": ModelPricing(
        model_id="o1",
        provider=Provider.OPENAI,
        model_type=ModelType.LLM,
        price_per_1k_tokens=None,
        max_tokens=200000,  # 200k context
        description="Previous full o-series reasoning model",
        metadata={
            "input_price_per_1m_tokens": 15.00,
            "cached_input_price_per_1m_tokens": 7.50,
            "output_price_per_1m_tokens": 60.00,
            "input_price_per_1k_tokens": 15.00 / 1000,
            "cached_input_price_per_1k_tokens": 7.50 / 1000,
            "output_price_per_1k_tokens": 60.00 / 1000,
            "category": "reasoning",
            "features": ["reasoning"],
        },
    ),
    "o1-pro": ModelPricing(
        model_id="o1-pro",
        provider=Provider.OPENAI,
        model_type=ModelType.LLM,
        price_per_1k_tokens=None,
        max_tokens=200000,
        description="Version of o1 with more compute for better responses",
        metadata={
            "input_price_per_1m_tokens": 150.00,
            "cached_input_price_per_1m_tokens": None,
            "output_price_per_1m_tokens": 600.00,
            "input_price_per_1k_tokens": 150.00 / 1000,
            "cached_input_price_per_1k_tokens": None,
            "output_price_per_1k_tokens": 600.00 / 1000,
            "category": "reasoning",
            "features": ["reasoning"],
        },
    ),
    "o1-mini": ModelPricing(
        model_id="o1-mini",
        provider=Provider.OPENAI,
        model_type=ModelType.LLM,
        price_per_1k_tokens=None,
        max_tokens=128000,
        description="A small model alternative to o1 (Deprecated)",
        metadata={
            "input_price_per_1m_tokens": 1.10,
            "cached_input_price_per_1m_tokens": 0.55,
            "output_price_per_1m_tokens": 4.40,
            "input_price_per_1k_tokens": 1.10 / 1000,
            "cached_input_price_per_1k_tokens": 0.55 / 1000,
            "output_price_per_1k_tokens": 4.40 / 1000,
            "category": "reasoning",
            "features": ["reasoning"],
            "deprecated": True,
        },
    ),
    "o3": ModelPricing(
        model_id="o3",
        provider=Provider.OPENAI,
        model_type=ModelType.LLM,
        price_per_1k_tokens=None,
        max_tokens=200000,
        description="Reasoning model for complex tasks, succeeded by GPT-5",
        metadata={
            "input_price_per_1m_tokens": 2.00,
            "cached_input_price_per_1m_tokens": 0.50,
            "output_price_per_1m_tokens": 8.00,
            "input_price_per_1k_tokens": 2.00 / 1000,
            "cached_input_price_per_1k_tokens": 0.50 / 1000,
            "output_price_per_1k_tokens": 8.00 / 1000,
            "category": "reasoning",
            "features": ["reasoning"],
        },
    ),
    "o3-pro": ModelPricing(
        model_id="o3-pro",
        provider=Provider.OPENAI,
        model_type=ModelType.LLM,
        price_per_1k_tokens=None,
        max_tokens=200000,
        description="Version of o3 with more compute for better responses",
        metadata={
            "input_price_per_1m_tokens": 20.00,
            "cached_input_price_per_1m_tokens": None,
            "output_price_per_1m_tokens": 80.00,
            "input_price_per_1k_tokens": 20.00 / 1000,
            "cached_input_price_per_1k_tokens": None,
            "output_price_per_1k_tokens": 80.00 / 1000,
            "category": "reasoning",
            "features": ["reasoning"],
        },
    ),
    "o3-mini": ModelPricing(
        model_id="o3-mini",
        provider=Provider.OPENAI,
        model_type=ModelType.LLM,
        price_per_1k_tokens=None,
        max_tokens=128000,
        description="A small model alternative to o3",
        metadata={
            "input_price_per_1m_tokens": 1.10,
            "cached_input_price_per_1m_tokens": 0.55,
            "output_price_per_1m_tokens": 4.40,
            "input_price_per_1k_tokens": 1.10 / 1000,
            "cached_input_price_per_1k_tokens": 0.55 / 1000,
            "output_price_per_1k_tokens": 4.40 / 1000,
            "category": "reasoning",
            "features": ["reasoning"],
        },
    ),
    "o3-deep-research": ModelPricing(
        model_id="o3-deep-research",
        provider=Provider.OPENAI,
        model_type=ModelType.LLM,
        price_per_1k_tokens=None,
        max_tokens=200000,
        description="Our most powerful deep research model",
        metadata={
            "input_price_per_1m_tokens": 10.00,
            "cached_input_price_per_1m_tokens": 2.50,
            "output_price_per_1m_tokens": 40.00,
            "input_price_per_1k_tokens": 10.00 / 1000,
            "cached_input_price_per_1k_tokens": 2.50 / 1000,
            "output_price_per_1k_tokens": 40.00 / 1000,
            "category": "reasoning",
            "features": ["reasoning", "research"],
        },
    ),
    "o4-mini": ModelPricing(
        model_id="o4-mini",
        provider=Provider.OPENAI,
        model_type=ModelType.LLM,
        price_per_1k_tokens=None,
        max_tokens=128000,
        description="Fast, cost-efficient reasoning model, succeeded by GPT-5 mini",
        metadata={
            "input_price_per_1m_tokens": 1.10,
            "cached_input_price_per_1m_tokens": 0.275,
            "output_price_per_1m_tokens": 4.40,
            "input_price_per_1k_tokens": 1.10 / 1000,
            "cached_input_price_per_1k_tokens": 0.275 / 1000,
            "output_price_per_1k_tokens": 4.40 / 1000,
            "category": "reasoning",
            "features": ["reasoning"],
        },
    ),
    "o4-mini-deep-research": ModelPricing(
        model_id="o4-mini-deep-research",
        provider=Provider.OPENAI,
        model_type=ModelType.LLM,
        price_per_1k_tokens=None,
        max_tokens=128000,
        description="Faster, more affordable deep research model",
        metadata={
            "input_price_per_1m_tokens": 2.00,
            "cached_input_price_per_1m_tokens": 0.50,
            "output_price_per_1m_tokens": 8.00,
            "input_price_per_1k_tokens": 2.00 / 1000,
            "cached_input_price_per_1k_tokens": 0.50 / 1000,
            "output_price_per_1k_tokens": 8.00 / 1000,
            "category": "reasoning",
            "features": ["reasoning", "research"],
        },
    ),
    
    # Search Models
    "gpt-5-search-api": ModelPricing(
        model_id="gpt-5-search-api",
        provider=Provider.OPENAI,
        model_type=ModelType.LLM,
        price_per_1k_tokens=None,
        max_tokens=128000,
        description="GPT-5 model for web search",
        metadata={
            "input_price_per_1m_tokens": 1.25,
            "cached_input_price_per_1m_tokens": 0.125,
            "output_price_per_1m_tokens": 10.00,
            "input_price_per_1k_tokens": 1.25 / 1000,
            "cached_input_price_per_1k_tokens": 0.125 / 1000,
            "output_price_per_1k_tokens": 10.00 / 1000,
            "category": "specialized",
            "features": ["search"],
        },
    ),
    "gpt-4o-mini-search-preview": ModelPricing(
        model_id="gpt-4o-mini-search-preview",
        provider=Provider.OPENAI,
        model_type=ModelType.LLM,
        price_per_1k_tokens=None,
        max_tokens=128000,
        description="Fast, affordable small model for web search",
        metadata={
            "input_price_per_1m_tokens": 0.15,
            "cached_input_price_per_1m_tokens": None,
            "output_price_per_1m_tokens": 0.60,
            "input_price_per_1k_tokens": 0.15 / 1000,
            "cached_input_price_per_1k_tokens": None,
            "output_price_per_1k_tokens": 0.60 / 1000,
            "category": "specialized",
            "features": ["search"],
        },
    ),
    "gpt-4o-search-preview": ModelPricing(
        model_id="gpt-4o-search-preview",
        provider=Provider.OPENAI,
        model_type=ModelType.LLM,
        price_per_1k_tokens=None,
        max_tokens=128000,
        description="GPT model for web search in Chat Completions",
        metadata={
            "input_price_per_1m_tokens": 2.50,
            "cached_input_price_per_1m_tokens": None,
            "output_price_per_1m_tokens": 10.00,
            "input_price_per_1k_tokens": 2.50 / 1000,
            "cached_input_price_per_1k_tokens": None,
            "output_price_per_1k_tokens": 10.00 / 1000,
            "category": "specialized",
            "features": ["search"],
        },
    ),
    
    # Specialized Models
    "computer-use-preview": ModelPricing(
        model_id="computer-use-preview",
        provider=Provider.OPENAI,
        model_type=ModelType.LLM,
        price_per_1k_tokens=None,
        max_tokens=128000,
        description="Specialized model for computer use tool",
        metadata={
            "input_price_per_1m_tokens": 3.00,
            "cached_input_price_per_1m_tokens": None,
            "output_price_per_1m_tokens": 12.00,
            "input_price_per_1k_tokens": 3.00 / 1000,
            "cached_input_price_per_1k_tokens": None,
            "output_price_per_1k_tokens": 12.00 / 1000,
            "category": "specialized",
            "features": ["computer-use"],
        },
    ),
    "codex-mini-latest": ModelPricing(
        model_id="codex-mini-latest",
        provider=Provider.OPENAI,
        model_type=ModelType.LLM,
        price_per_1k_tokens=None,
        max_tokens=128000,
        description="Fast reasoning model optimized for the Codex CLI",
        metadata={
            "input_price_per_1m_tokens": 1.50,
            "cached_input_price_per_1m_tokens": 0.375,
            "output_price_per_1m_tokens": 6.00,
            "input_price_per_1k_tokens": 1.50 / 1000,
            "cached_input_price_per_1k_tokens": 0.375 / 1000,
            "output_price_per_1k_tokens": 6.00 / 1000,
            "category": "specialized",
            "features": ["coding"],
        },
    ),
    
    # Legacy Models
    "gpt-4-turbo": ModelPricing(
        model_id="gpt-4-turbo",
        provider=Provider.OPENAI,
        model_type=ModelType.LLM,
        price_per_1k_tokens=None,
        max_tokens=128000,
        description="An older high-intelligence GPT model",
        metadata={
            "input_price_per_1m_tokens": 10.00,  # Estimated
            "cached_input_price_per_1m_tokens": None,
            "output_price_per_1m_tokens": 30.00,  # Estimated
            "input_price_per_1k_tokens": 10.00 / 1000,
            "cached_input_price_per_1k_tokens": None,
            "output_price_per_1k_tokens": 30.00 / 1000,
            "category": "legacy",
        },
    ),
    "gpt-4": ModelPricing(
        model_id="gpt-4",
        provider=Provider.OPENAI,
        model_type=ModelType.LLM,
        price_per_1k_tokens=None,
        max_tokens=8192,
        description="An older high-intelligence GPT model",
        metadata={
            "input_price_per_1m_tokens": 30.00,  # Estimated
            "cached_input_price_per_1m_tokens": None,
            "output_price_per_1m_tokens": 60.00,  # Estimated
            "input_price_per_1k_tokens": 30.00 / 1000,
            "cached_input_price_per_1k_tokens": None,
            "output_price_per_1k_tokens": 60.00 / 1000,
            "category": "legacy",
        },
    ),
    "gpt-3.5-turbo": ModelPricing(
        model_id="gpt-3.5-turbo",
        provider=Provider.OPENAI,
        model_type=ModelType.LLM,
        price_per_1k_tokens=None,
        max_tokens=16385,
        description="Legacy GPT model for cheaper chat and non-chat tasks",
        metadata={
            "input_price_per_1m_tokens": 0.50,  # Estimated
            "cached_input_price_per_1m_tokens": None,
            "output_price_per_1m_tokens": 1.50,  # Estimated
            "input_price_per_1k_tokens": 0.50 / 1000,
            "cached_input_price_per_1k_tokens": None,
            "output_price_per_1k_tokens": 1.50 / 1000,
            "category": "legacy",
        },
    ),
    "chatgpt-4o-latest": ModelPricing(
        model_id="chatgpt-4o-latest",
        provider=Provider.OPENAI,
        model_type=ModelType.LLM,
        price_per_1k_tokens=None,
        max_tokens=128000,
        description="GPT-4o model used in ChatGPT",
        metadata={
            "input_price_per_1m_tokens": 2.50,
            "cached_input_price_per_1m_tokens": 1.25,
            "output_price_per_1m_tokens": 10.00,
            "input_price_per_1k_tokens": 2.50 / 1000,
            "cached_input_price_per_1k_tokens": 1.25 / 1000,
            "output_price_per_1k_tokens": 10.00 / 1000,
            "category": "standard",
        },
    ),
}

# Combine all OpenAI LLM models
OPENAI_LLM_MODELS_ALL = OPENAI_LLM_MODELS


# ============================================================================
# ANTHROPIC CLAUDE LLM MODELS
# ============================================================================

ANTHROPIC_LLM_MODELS: Dict[str, ModelPricing] = {
    # Claude Sonnet 4.5
    "claude-sonnet-4-5-20250929": ModelPricing(
        model_id="claude-sonnet-4-5-20250929",
        provider=Provider.ANTHROPIC,
        model_type=ModelType.LLM,
        price_per_1k_tokens=None,
        max_tokens=64000,  # 64K max output
        description="Our smartest model for complex agents and coding",
        metadata={
            "input_price_per_1m_tokens": 3.00,
            "cached_input_price_per_1m_tokens_5m": 3.75,  # 5 minute cache writes
            "cached_input_price_per_1m_tokens_1h": 6.00,  # 1 hour cache writes
            "cache_hit_price_per_1m_tokens": 0.30,  # Cache hits & refreshes
            "output_price_per_1m_tokens": 15.00,
            "batch_input_price_per_1m_tokens": 1.50,  # 50% discount
            "batch_output_price_per_1m_tokens": 7.50,  # 50% discount
            "input_price_per_1k_tokens": 3.00 / 1000,
            "cached_input_price_per_1k_tokens": 0.30 / 1000,  # Default to cache hit pricing
            "output_price_per_1k_tokens": 15.00 / 1000,
            "context_window": 200000,  # 200K tokens, 1M available in beta
            "context_window_1m_beta": True,
            "long_context_input_price_per_1m_tokens": 6.00,  # > 200K tokens
            "long_context_output_price_per_1m_tokens": 22.50,  # > 200K tokens
            "category": "frontier",
            "features": ["extended_thinking", "priority_tier", "coding", "agents"],
            "api_alias": "claude-sonnet-4-5",
        },
    ),
    "claude-sonnet-4-5": ModelPricing(
        model_id="claude-sonnet-4-5",
        provider=Provider.ANTHROPIC,
        model_type=ModelType.LLM,
        price_per_1k_tokens=None,
        max_tokens=64000,
        description="Our smartest model for complex agents and coding (alias)",
        metadata={
            "input_price_per_1m_tokens": 3.00,
            "cached_input_price_per_1m_tokens_5m": 3.75,
            "cached_input_price_per_1m_tokens_1h": 6.00,
            "cache_hit_price_per_1m_tokens": 0.30,
            "output_price_per_1m_tokens": 15.00,
            "batch_input_price_per_1m_tokens": 1.50,
            "batch_output_price_per_1m_tokens": 7.50,
            "input_price_per_1k_tokens": 3.00 / 1000,
            "cached_input_price_per_1k_tokens": 0.30 / 1000,
            "output_price_per_1k_tokens": 15.00 / 1000,
            "context_window": 200000,
            "context_window_1m_beta": True,
            "long_context_input_price_per_1m_tokens": 6.00,
            "long_context_output_price_per_1m_tokens": 22.50,
            "category": "frontier",
            "features": ["extended_thinking", "priority_tier", "coding", "agents"],
            "is_alias": True,
            "aliases_to": "claude-sonnet-4-5-20250929",
        },
    ),
    
    # Claude Sonnet 4
    "claude-sonnet-4-20250514": ModelPricing(
        model_id="claude-sonnet-4-20250514",
        provider=Provider.ANTHROPIC,
        model_type=ModelType.LLM,
        price_per_1k_tokens=None,
        max_tokens=64000,
        description="Claude Sonnet 4 model",
        metadata={
            "input_price_per_1m_tokens": 3.00,
            "cached_input_price_per_1m_tokens_5m": 3.75,
            "cached_input_price_per_1m_tokens_1h": 6.00,
            "cache_hit_price_per_1m_tokens": 0.30,
            "output_price_per_1m_tokens": 15.00,
            "batch_input_price_per_1m_tokens": 1.50,
            "batch_output_price_per_1m_tokens": 7.50,
            "input_price_per_1k_tokens": 3.00 / 1000,
            "cached_input_price_per_1k_tokens": 0.30 / 1000,
            "output_price_per_1k_tokens": 15.00 / 1000,
            "context_window": 200000,
            "context_window_1m_beta": True,
            "long_context_input_price_per_1m_tokens": 6.00,
            "long_context_output_price_per_1m_tokens": 22.50,
            "category": "frontier",
            "features": ["extended_thinking", "priority_tier"],
        },
    ),
    
    # Claude Haiku 4.5
    "claude-haiku-4-5-20251001": ModelPricing(
        model_id="claude-haiku-4-5-20251001",
        provider=Provider.ANTHROPIC,
        model_type=ModelType.LLM,
        price_per_1k_tokens=None,
        max_tokens=64000,
        description="Our fastest model with near-frontier intelligence",
        metadata={
            "input_price_per_1m_tokens": 1.00,
            "cached_input_price_per_1m_tokens_5m": 1.25,
            "cached_input_price_per_1m_tokens_1h": 2.00,
            "cache_hit_price_per_1m_tokens": 0.10,
            "output_price_per_1m_tokens": 5.00,
            "batch_input_price_per_1m_tokens": 0.50,
            "batch_output_price_per_1m_tokens": 2.50,
            "input_price_per_1k_tokens": 1.00 / 1000,
            "cached_input_price_per_1k_tokens": 0.10 / 1000,
            "output_price_per_1k_tokens": 5.00 / 1000,
            "context_window": 200000,
            "category": "standard",
            "features": ["extended_thinking", "priority_tier"],
            "api_alias": "claude-haiku-4-5",
        },
    ),
    "claude-haiku-4-5": ModelPricing(
        model_id="claude-haiku-4-5",
        provider=Provider.ANTHROPIC,
        model_type=ModelType.LLM,
        price_per_1k_tokens=None,
        max_tokens=64000,
        description="Our fastest model with near-frontier intelligence (alias)",
        metadata={
            "input_price_per_1m_tokens": 1.00,
            "cached_input_price_per_1m_tokens_5m": 1.25,
            "cached_input_price_per_1m_tokens_1h": 2.00,
            "cache_hit_price_per_1m_tokens": 0.10,
            "output_price_per_1m_tokens": 5.00,
            "batch_input_price_per_1m_tokens": 0.50,
            "batch_output_price_per_1m_tokens": 2.50,
            "input_price_per_1k_tokens": 1.00 / 1000,
            "cached_input_price_per_1k_tokens": 0.10 / 1000,
            "output_price_per_1k_tokens": 5.00 / 1000,
            "context_window": 200000,
            "category": "standard",
            "features": ["extended_thinking", "priority_tier"],
            "is_alias": True,
            "aliases_to": "claude-haiku-4-5-20251001",
        },
    ),
    
    # Claude Haiku 3.5
    "claude-haiku-3-5-20241022": ModelPricing(
        model_id="claude-haiku-3-5-20241022",
        provider=Provider.ANTHROPIC,
        model_type=ModelType.LLM,
        price_per_1k_tokens=None,
        max_tokens=64000,
        description="Claude Haiku 3.5 model",
        metadata={
            "input_price_per_1m_tokens": 0.80,
            "cached_input_price_per_1m_tokens_5m": 1.00,
            "cached_input_price_per_1m_tokens_1h": 1.60,
            "cache_hit_price_per_1m_tokens": 0.08,
            "output_price_per_1m_tokens": 4.00,
            "batch_input_price_per_1m_tokens": 0.40,
            "batch_output_price_per_1m_tokens": 2.00,
            "input_price_per_1k_tokens": 0.80 / 1000,
            "cached_input_price_per_1k_tokens": 0.08 / 1000,
            "output_price_per_1k_tokens": 4.00 / 1000,
            "context_window": 200000,
            "category": "standard",
        },
    ),
    
    # Claude Opus 4.1
    "claude-opus-4-1-20250805": ModelPricing(
        model_id="claude-opus-4-1-20250805",
        provider=Provider.ANTHROPIC,
        model_type=ModelType.LLM,
        price_per_1k_tokens=None,
        max_tokens=32000,  # 32K max output
        description="Exceptional model for specialized reasoning tasks",
        metadata={
            "input_price_per_1m_tokens": 15.00,
            "cached_input_price_per_1m_tokens_5m": 18.75,
            "cached_input_price_per_1m_tokens_1h": 30.00,
            "cache_hit_price_per_1m_tokens": 1.50,
            "output_price_per_1m_tokens": 75.00,
            "batch_input_price_per_1m_tokens": 7.50,
            "batch_output_price_per_1m_tokens": 37.50,
            "input_price_per_1k_tokens": 15.00 / 1000,
            "cached_input_price_per_1k_tokens": 1.50 / 1000,
            "output_price_per_1k_tokens": 75.00 / 1000,
            "context_window": 200000,
            "category": "premium",
            "features": ["extended_thinking", "priority_tier", "reasoning"],
            "api_alias": "claude-opus-4-1",
        },
    ),
    "claude-opus-4-1": ModelPricing(
        model_id="claude-opus-4-1",
        provider=Provider.ANTHROPIC,
        model_type=ModelType.LLM,
        price_per_1k_tokens=None,
        max_tokens=32000,
        description="Exceptional model for specialized reasoning tasks (alias)",
        metadata={
            "input_price_per_1m_tokens": 15.00,
            "cached_input_price_per_1m_tokens_5m": 18.75,
            "cached_input_price_per_1m_tokens_1h": 30.00,
            "cache_hit_price_per_1m_tokens": 1.50,
            "output_price_per_1m_tokens": 75.00,
            "batch_input_price_per_1m_tokens": 7.50,
            "batch_output_price_per_1m_tokens": 37.50,
            "input_price_per_1k_tokens": 15.00 / 1000,
            "cached_input_price_per_1k_tokens": 1.50 / 1000,
            "output_price_per_1k_tokens": 75.00 / 1000,
            "context_window": 200000,
            "category": "premium",
            "features": ["extended_thinking", "priority_tier", "reasoning"],
            "is_alias": True,
            "aliases_to": "claude-opus-4-1-20250805",
        },
    ),
    
    # Claude Opus 4.5
    "claude-opus-4-5-20251101": ModelPricing(
        model_id="claude-opus-4-5-20251101",
        provider=Provider.ANTHROPIC,
        model_type=ModelType.LLM,
        price_per_1k_tokens=None,
        max_tokens=64000,  # 64K max output
        description="Premium model combining maximum intelligence with practical performance",
        metadata={
            "input_price_per_1m_tokens": 5.00,
            "cached_input_price_per_1m_tokens_5m": 6.25,
            "cached_input_price_per_1m_tokens_1h": 10.00,
            "cache_hit_price_per_1m_tokens": 0.50,
            "output_price_per_1m_tokens": 25.00,
            "batch_input_price_per_1m_tokens": 2.50,  # 50% discount
            "batch_output_price_per_1m_tokens": 12.50,  # 50% discount
            "input_price_per_1k_tokens": 5.00 / 1000,
            "cached_input_price_per_1k_tokens": 0.50 / 1000,
            "output_price_per_1k_tokens": 25.00 / 1000,
            "context_window": 200000,
            "category": "premium",
            "features": ["extended_thinking", "priority_tier"],
            "api_alias": "claude-opus-4-5",
        },
    ),
    "claude-opus-4-5": ModelPricing(
        model_id="claude-opus-4-5",
        provider=Provider.ANTHROPIC,
        model_type=ModelType.LLM,
        price_per_1k_tokens=None,
        max_tokens=64000,
        description="Premium model combining maximum intelligence with practical performance (alias)",
        metadata={
            "input_price_per_1m_tokens": 5.00,
            "cached_input_price_per_1m_tokens_5m": 6.25,
            "cached_input_price_per_1m_tokens_1h": 10.00,
            "cache_hit_price_per_1m_tokens": 0.50,
            "output_price_per_1m_tokens": 25.00,
            "batch_input_price_per_1m_tokens": 2.50,
            "batch_output_price_per_1m_tokens": 12.50,
            "input_price_per_1k_tokens": 5.00 / 1000,
            "cached_input_price_per_1k_tokens": 0.50 / 1000,
            "output_price_per_1k_tokens": 25.00 / 1000,
            "context_window": 200000,
            "category": "premium",
            "features": ["extended_thinking", "priority_tier"],
            "is_alias": True,
            "aliases_to": "claude-opus-4-5-20251101",
        },
    ),
    
    # Claude Opus 4
    "claude-opus-4-20250514": ModelPricing(
        model_id="claude-opus-4-20250514",
        provider=Provider.ANTHROPIC,
        model_type=ModelType.LLM,
        price_per_1k_tokens=None,
        max_tokens=32000,
        description="Claude Opus 4 model",
        metadata={
            "input_price_per_1m_tokens": 15.00,
            "cached_input_price_per_1m_tokens_5m": 18.75,
            "cached_input_price_per_1m_tokens_1h": 30.00,
            "cache_hit_price_per_1m_tokens": 1.50,
            "output_price_per_1m_tokens": 75.00,
            "batch_input_price_per_1m_tokens": 7.50,
            "batch_output_price_per_1m_tokens": 37.50,
            "input_price_per_1k_tokens": 15.00 / 1000,
            "cached_input_price_per_1k_tokens": 1.50 / 1000,
            "output_price_per_1k_tokens": 75.00 / 1000,
            "context_window": 200000,
            "category": "premium",
            "features": ["extended_thinking", "priority_tier"],
        },
    ),
    
    # Legacy/Deprecated models
    "claude-sonnet-3-7-20240229": ModelPricing(
        model_id="claude-sonnet-3-7-20240229",
        provider=Provider.ANTHROPIC,
        model_type=ModelType.LLM,
        price_per_1k_tokens=None,
        max_tokens=64000,
        description="Claude Sonnet 3.7 (deprecated)",
        metadata={
            "input_price_per_1m_tokens": 3.00,
            "cached_input_price_per_1m_tokens_5m": 3.75,
            "cached_input_price_per_1m_tokens_1h": 6.00,
            "cache_hit_price_per_1m_tokens": 0.30,
            "output_price_per_1m_tokens": 15.00,
            "batch_input_price_per_1m_tokens": 1.50,
            "batch_output_price_per_1m_tokens": 7.50,
            "input_price_per_1k_tokens": 3.00 / 1000,
            "cached_input_price_per_1k_tokens": 0.30 / 1000,
            "output_price_per_1k_tokens": 15.00 / 1000,
            "context_window": 200000,
            "category": "legacy",
            "deprecated": True,
        },
    ),
    "claude-opus-3-20240229": ModelPricing(
        model_id="claude-opus-3-20240229",
        provider=Provider.ANTHROPIC,
        model_type=ModelType.LLM,
        price_per_1k_tokens=None,
        max_tokens=32000,
        description="Claude Opus 3 (deprecated)",
        metadata={
            "input_price_per_1m_tokens": 15.00,
            "cached_input_price_per_1m_tokens_5m": 18.75,
            "cached_input_price_per_1m_tokens_1h": 30.00,
            "cache_hit_price_per_1m_tokens": 1.50,
            "output_price_per_1m_tokens": 75.00,
            "batch_input_price_per_1m_tokens": 7.50,
            "batch_output_price_per_1m_tokens": 37.50,
            "input_price_per_1k_tokens": 15.00 / 1000,
            "cached_input_price_per_1k_tokens": 1.50 / 1000,
            "output_price_per_1k_tokens": 75.00 / 1000,
            "context_window": 200000,
            "category": "legacy",
            "deprecated": True,
        },
    ),
    "claude-haiku-3-20240307": ModelPricing(
        model_id="claude-haiku-3-20240307",
        provider=Provider.ANTHROPIC,
        model_type=ModelType.LLM,
        price_per_1k_tokens=None,
        max_tokens=64000,
        description="Claude Haiku 3 (deprecated)",
        metadata={
            "input_price_per_1m_tokens": 0.25,
            "cached_input_price_per_1m_tokens_5m": 0.30,
            "cached_input_price_per_1m_tokens_1h": 0.50,
            "cache_hit_price_per_1m_tokens": 0.03,
            "output_price_per_1m_tokens": 1.25,
            "batch_input_price_per_1m_tokens": 0.125,
            "batch_output_price_per_1m_tokens": 0.625,
            "input_price_per_1k_tokens": 0.25 / 1000,
            "cached_input_price_per_1k_tokens": 0.03 / 1000,
            "output_price_per_1k_tokens": 1.25 / 1000,
            "context_window": 200000,
            "category": "legacy",
            "deprecated": True,
        },
    ),
}

# Combine all Anthropic LLM models
ANTHROPIC_LLM_MODELS_ALL = ANTHROPIC_LLM_MODELS

